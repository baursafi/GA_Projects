{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "69b9a648-bcc7-490d-9f9b-ea244d156bd6"
   },
   "source": [
    "# Web Scraping for Indeed.com & Predicting Salaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "34681254-c802-462f-829d-8894d0772d08"
   },
   "source": [
    "In this project, we will practice two major skills: collecting data by scraping a website and then building a binary classifier.\n",
    "\n",
    "We are going to collect salary information on data science jobs in a variety of markets. Then using the location, title, and summary of the job we will attempt to predict the salary of the job. For job posting sites, this would be extraordinarily useful. While most listings DO NOT come with salary information (as you will see in this exercise), being to able extrapolate or predict the expected salaries from other listings can help guide negotiations.\n",
    "\n",
    "Normally, we could use regression for this task; however, we will convert this problem into classification and use a random forest classifier, as well as another classifier of your choice; either logistic regression, SVM, or KNN. \n",
    "\n",
    "- **Question**: Why would we want this to be a classification problem?\n",
    "- **Answer**: While more precision may be better, there is a fair amount of natural variance in job salaries - predicting a range be may be useful.\n",
    "\n",
    "Therefore, the first part of the assignment will be focused on scraping Indeed.com. In the second, we'll focus on using listings with salary information to build a model and predict additional salaries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "a948d79c-5527-4c0d-ab23-f5d43ce72056"
   },
   "source": [
    "### Scraping job listings from Indeed.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": true,
    "id": "7203e0c9-e437-4802-a6ad-7dc464f94436"
   },
   "source": [
    "We will be scraping job listings from Indeed.com using BeautifulSoup. Luckily, Indeed.com is a simple text page where we can easily find relevant entries.\n",
    "\n",
    "First, look at the source of an Indeed.com page: (http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l=New+York&start=10\")\n",
    "\n",
    "Notice, each job listing is underneath a `div` tag with a class name of `result`. We can use BeautifulSoup to extract those. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up a request (using requests) to the URL below. Use BeautifulSoup to parse the page and extract all results (HINT: Look for div tags with class name result)\n",
    "The URL here has many query parameters\n",
    "- q for the job search\n",
    "- This is followed by \"+20,000\" to return results with salaries (or expected salaries >$20,000)\n",
    "- l for a location\n",
    "- start for what result number to start on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#URL = \"http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l=New+York&start=10\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import bs4\n",
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = pd.read_csv('../../project_3_data/jobsdf_exp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "labels [ True False False False False False  True  True False  True  True  True\n False False  True False False False False False False False  True False\n  True False  True False False False  True False  True False  True  True\n  True  True  True False False False False  True  True False False False\n  True False False False  True False False False  True False False  True\n False False False False False False False False  True False False False\n False False False False  True False  True False False False False  True\n False  True  True False False False  True False  True False False False\n False  True  True  True False False False False False False False  True\n False False False False False False False False False False] not contained in axis",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-b1ed800a9705>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mjobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'first'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#jobs.drop('Unnamed: 0', axis = 1, inplace = True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mjobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msalarytxt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mjobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mjobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msalarytxt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/baurjansafi/anaconda/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, level, inplace, errors)\u001b[0m\n\u001b[1;32m   2048\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2049\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2050\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2051\u001b[0m             \u001b[0mdropped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2052\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/baurjansafi/anaconda/lib/python2.7/site-packages/pandas/core/indexes/base.pyc\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   3573\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'ignore'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3574\u001b[0m                 raise ValueError('labels %s not contained in axis' %\n\u001b[0;32m-> 3575\u001b[0;31m                                  labels[mask])\n\u001b[0m\u001b[1;32m   3576\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3577\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: labels [ True False False False False False  True  True False  True  True  True\n False False  True False False False False False False False  True False\n  True False  True False False False  True False  True False  True  True\n  True  True  True False False False False  True  True False False False\n  True False False False  True False False False  True False False  True\n False False False False False False False False  True False False False\n False False False False  True False  True False False False False  True\n False  True  True False False False  True False  True False False False\n False  True  True  True False False False False False False False  True\n False False False False False False False False False False] not contained in axis"
     ]
    }
   ],
   "source": [
    "jobs.dropna(inplace=True)\n",
    "jobs.drop_duplicates(keep = 'first')\n",
    "#jobs.drop('Unnamed: 0', axis = 1, inplace = True)\n",
    "jobs.drop(jobs.salarytxt == 0, inplace = True)\n",
    "print jobs.shape\n",
    "jobs.salarytxt.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the unnamde column - it hid a lot of duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jobs = jobs.drop('Unnamed: 0',axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14562"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs.duplicated().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7934, 6)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs = jobs.drop_duplicates()\n",
    "jobs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(405, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jobtitle</th>\n",
       "      <th>company</th>\n",
       "      <th>city</th>\n",
       "      <th>location</th>\n",
       "      <th>salarytxt</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>entry level – research analyst/editor/content ...</td>\n",
       "      <td>XG Consultants Group, Inc.</td>\n",
       "      <td>New+York%2CNY</td>\n",
       "      <td>New York, NY 10017 (Midtown area)</td>\n",
       "      <td>15.0</td>\n",
       "      <td>job overview: xg consultants group is looking ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>scientist / chemist</td>\n",
       "      <td>On-Board Services</td>\n",
       "      <td>New+York%2CNY</td>\n",
       "      <td>Franklin Lakes, NJ</td>\n",
       "      <td>40.0</td>\n",
       "      <td>hiring a contract scientist / chemist. experie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>technician b</td>\n",
       "      <td>Columbia University</td>\n",
       "      <td>New+York%2CNY</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>23.0</td>\n",
       "      <td>experience analyzing large ngs data; the indiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2539</th>\n",
       "      <td>data scientist</td>\n",
       "      <td>Workbridge Associates</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>a major healthcare corporation that is buildin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2766</th>\n",
       "      <td>medical technologist ii – microbiology- john h...</td>\n",
       "      <td>Cook County Health &amp; Hospitals System</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>24.0</td>\n",
       "      <td>medical technologist (mt), clinical laboratory...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2774</th>\n",
       "      <td>medical technologist ii – chemistry- john h. s...</td>\n",
       "      <td>Cook County Health &amp; Hospitals System</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>24.0</td>\n",
       "      <td>medical technologist (mt), clinical laboratory...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2818</th>\n",
       "      <td>medical technologist iii - john h. stroger hos...</td>\n",
       "      <td>Cook County Health &amp; Hospitals System</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>28.0</td>\n",
       "      <td>an accredited medical technologist (amt), clin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2987</th>\n",
       "      <td>data scientist</td>\n",
       "      <td>PDDN Inc</td>\n",
       "      <td>San+Francisco</td>\n",
       "      <td>San Mateo, CA</td>\n",
       "      <td>60.0</td>\n",
       "      <td>data analytics experience do you have:. the te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3041</th>\n",
       "      <td>video machine learning - field position/yard l...</td>\n",
       "      <td>WingWarp Inc.</td>\n",
       "      <td>San+Francisco</td>\n",
       "      <td>San Francisco, CA 94158 (South Of Market area)</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>we would like to process real time video of a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3367</th>\n",
       "      <td>sr associate research operations - 3289</td>\n",
       "      <td>Amerit Consulting</td>\n",
       "      <td>San+Francisco</td>\n",
       "      <td>South San Francisco, CA 94080</td>\n",
       "      <td>34.0</td>\n",
       "      <td>the successful applicant must be able to indep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4009</th>\n",
       "      <td>bench scientist i (t-cell, cart, single cell s...</td>\n",
       "      <td>Aequor Technologies</td>\n",
       "      <td>San+Francisco</td>\n",
       "      <td>South San Francisco, CA 94080</td>\n",
       "      <td>38.0</td>\n",
       "      <td>job title:  bench scientist i location:  san f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4992</th>\n",
       "      <td>research engineering/ scientist assistant</td>\n",
       "      <td>University of Texas at Austin</td>\n",
       "      <td>Austin</td>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>2666.0</td>\n",
       "      <td>obtain phenotypic data from biological specime...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5004</th>\n",
       "      <td>research engineering/ scientist associate i (e...</td>\n",
       "      <td>University of Texas at Austin</td>\n",
       "      <td>Austin</td>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>2916.0</td>\n",
       "      <td>purpose to conduct scientific research in dr. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5134</th>\n",
       "      <td>engineering scientist associate - research sof...</td>\n",
       "      <td>University of Texas at Austin</td>\n",
       "      <td>Austin</td>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>two or more years experience with data managem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5135</th>\n",
       "      <td>engineering scientist associate - research sof...</td>\n",
       "      <td>University of Texas at Austin</td>\n",
       "      <td>Austin</td>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>two or more years experience with data managem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5138</th>\n",
       "      <td>engineering scientist - senior research softwa...</td>\n",
       "      <td>University of Texas at Austin</td>\n",
       "      <td>Austin</td>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>6250.0</td>\n",
       "      <td>experience implementing large data processing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5139</th>\n",
       "      <td>research engineering/ scientist associate i (e...</td>\n",
       "      <td>University of Texas at Austin</td>\n",
       "      <td>Austin</td>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>4166.0</td>\n",
       "      <td>software or data carpentry concepts; data fram...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5142</th>\n",
       "      <td>research engineering/ scientist associate i (e...</td>\n",
       "      <td>University of Texas at Austin</td>\n",
       "      <td>Austin</td>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>4166.0</td>\n",
       "      <td>software or data carpentry concepts; collabora...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5151</th>\n",
       "      <td>social science/humanities research associate v...</td>\n",
       "      <td>University of Texas at Austin</td>\n",
       "      <td>Austin</td>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>5666.0</td>\n",
       "      <td>analyze data using tableau; the survey coordin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5249</th>\n",
       "      <td>research associate</td>\n",
       "      <td>Unigen</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>Seattle, WA 98121 (Belltown area)</td>\n",
       "      <td>20.0</td>\n",
       "      <td>assist scientists in writing technical reports...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5260</th>\n",
       "      <td>digital signal processing/dsp engineer - contract</td>\n",
       "      <td>Vertisystem</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>Redmond, WA</td>\n",
       "      <td>70.0</td>\n",
       "      <td>work with research scientists, acoustic engine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6232</th>\n",
       "      <td>clinical laboratory scientist i (blood bank)</td>\n",
       "      <td>Los Angeles County Department of Human Resources</td>\n",
       "      <td>Los+Angeles</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>7046.0</td>\n",
       "      <td>enters test results, quality control and impro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6303</th>\n",
       "      <td>data scientist / analyst</td>\n",
       "      <td>Platinum Enterprise Solutions</td>\n",
       "      <td>Los+Angeles</td>\n",
       "      <td>Los Angeles, CA 90001</td>\n",
       "      <td>50.0</td>\n",
       "      <td>data scientist/analyst6+ months contractplaya ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7635</th>\n",
       "      <td>hsc sr research scientist</td>\n",
       "      <td>Texas Tech Univ Health Sciences Ctr</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>Dallas-Fort Worth, TX</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>assist with all aspects of data collection. co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7750</th>\n",
       "      <td>senior data scientist - dallas,tx</td>\n",
       "      <td>Themesoft Inc</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>Dallas, TX</td>\n",
       "      <td>50.0</td>\n",
       "      <td>senior data scientist *location:. experience w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7952</th>\n",
       "      <td>corporate research analyst</td>\n",
       "      <td>DiscoverOrg</td>\n",
       "      <td>Portland%2COR</td>\n",
       "      <td>Vancouver, WA</td>\n",
       "      <td>15.0</td>\n",
       "      <td>verify entered data by reviewing, deleting, or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7971</th>\n",
       "      <td>senior analyst, load research (r17-196)</td>\n",
       "      <td>Portland General Electric</td>\n",
       "      <td>Portland%2COR</td>\n",
       "      <td>Portland, OR 97204 (Downtown area)</td>\n",
       "      <td>3378.0</td>\n",
       "      <td>maintain large databases and data sets. manipu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7995</th>\n",
       "      <td>subject matter expert/artificial intelligence</td>\n",
       "      <td>Staff Finders Technical Inc</td>\n",
       "      <td>Portland%2COR</td>\n",
       "      <td>Hillsboro, OR</td>\n",
       "      <td>70.0</td>\n",
       "      <td>create technical content to support software d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8057</th>\n",
       "      <td>office assistant/receptionist sr.</td>\n",
       "      <td>Arizona State University</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>Tempe, AZ</td>\n",
       "      <td>19200.0</td>\n",
       "      <td>collects data to maintain such records. enters...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8078</th>\n",
       "      <td>customer service / research analyst</td>\n",
       "      <td>All About People</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>Phoenix, AZ 85007 (Central City area)</td>\n",
       "      <td>13.0</td>\n",
       "      <td>enter data, compiles and compose data reports....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8588</th>\n",
       "      <td>data analyst oil and gas market research exper...</td>\n",
       "      <td>Adecco: USA</td>\n",
       "      <td>Houston</td>\n",
       "      <td>Spring, TX</td>\n",
       "      <td>55.0</td>\n",
       "      <td>demonstrated experience in creating growth and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8705</th>\n",
       "      <td>data analysis intern</td>\n",
       "      <td>hear.com</td>\n",
       "      <td>Miami</td>\n",
       "      <td>Miami, FL 33138 (Upper Eastside area)</td>\n",
       "      <td>12.0</td>\n",
       "      <td>hear.com, the leading innovator in providing m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8766</th>\n",
       "      <td>analytical r&amp;d associate scientist 717 (id#014)</td>\n",
       "      <td>The Staffing Resource Group, Inc</td>\n",
       "      <td>Miami</td>\n",
       "      <td>Miami, FL</td>\n",
       "      <td>25.0</td>\n",
       "      <td>analytical research &amp; development associate sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8867</th>\n",
       "      <td>software developer iii</td>\n",
       "      <td>Nextgen Technologies</td>\n",
       "      <td>Boston</td>\n",
       "      <td>Cambridge, MA</td>\n",
       "      <td>100.0</td>\n",
       "      <td>the candidate will be working with a team of d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9103</th>\n",
       "      <td>bench scientist i-44402</td>\n",
       "      <td>Makro</td>\n",
       "      <td>Boston</td>\n",
       "      <td>Andover, MA</td>\n",
       "      <td>39.0</td>\n",
       "      <td>we are looking for a scientist passionate abou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9425</th>\n",
       "      <td>bench scientist</td>\n",
       "      <td>Fortira</td>\n",
       "      <td>Boston</td>\n",
       "      <td>Andover, MA</td>\n",
       "      <td>24.0</td>\n",
       "      <td>junior scientist or lab associate. other exper...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9503</th>\n",
       "      <td>scientist ii</td>\n",
       "      <td>Apex Life Sciences</td>\n",
       "      <td>Boston</td>\n",
       "      <td>Canton, MA</td>\n",
       "      <td>38.0</td>\n",
       "      <td>experience with data bases is a plus. employ i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10789</th>\n",
       "      <td>associate scientist</td>\n",
       "      <td>Hunter International</td>\n",
       "      <td>San+Diego</td>\n",
       "      <td>San Diego, CA</td>\n",
       "      <td>28.0</td>\n",
       "      <td>compile data and records results. analyzes dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11043</th>\n",
       "      <td>associate scientist</td>\n",
       "      <td>On-Board Services</td>\n",
       "      <td>Baltimore</td>\n",
       "      <td>Sparks, MD</td>\n",
       "      <td>15.0</td>\n",
       "      <td>works with sap enterprise system to enter labo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11403</th>\n",
       "      <td>machine learning engineer</td>\n",
       "      <td>Consultative Search Group</td>\n",
       "      <td>San+Jose</td>\n",
       "      <td>Santa Clara, CA</td>\n",
       "      <td>85.0</td>\n",
       "      <td>data mining and machine learning experience in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11575</th>\n",
       "      <td>data scientist (contract-to-hire)</td>\n",
       "      <td>Jobspring Partners</td>\n",
       "      <td>San+Jose</td>\n",
       "      <td>San Jose, CA 95113 (Downtown area)</td>\n",
       "      <td>80.0</td>\n",
       "      <td>experience with data modeling. a scaling start...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11756</th>\n",
       "      <td>administrative assistant - pleasanton, ca</td>\n",
       "      <td>Q-Chem, Inc.</td>\n",
       "      <td>San+Jose</td>\n",
       "      <td>Pleasanton, CA 94588</td>\n",
       "      <td>17.0</td>\n",
       "      <td>candidate must have earned a high school diplo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12037</th>\n",
       "      <td>senior data scientist (contract)</td>\n",
       "      <td>Workbridge Associates</td>\n",
       "      <td>San+Jose</td>\n",
       "      <td>San Jose, CA 95113 (Downtown area)</td>\n",
       "      <td>100.0</td>\n",
       "      <td>an industry-leading human resources software s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12177</th>\n",
       "      <td>part time marketing intern</td>\n",
       "      <td>eComtics, Inc</td>\n",
       "      <td>San+Jose</td>\n",
       "      <td>Cupertino, CA 95014</td>\n",
       "      <td>12.0</td>\n",
       "      <td>no data scientist, engineers, operation team a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12928</th>\n",
       "      <td>clinical data analyst/scientist/engineer</td>\n",
       "      <td>Volt Workforce Solutions</td>\n",
       "      <td>Minneapolis</td>\n",
       "      <td>Saint Paul, MN</td>\n",
       "      <td>35.0</td>\n",
       "      <td>under direction, the candidate will process da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12930</th>\n",
       "      <td>legal research analyst</td>\n",
       "      <td>Thomson Reuters</td>\n",
       "      <td>Minneapolis</td>\n",
       "      <td>Eagan, MN</td>\n",
       "      <td>23.0</td>\n",
       "      <td>the legal research analyst position is primari...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12941</th>\n",
       "      <td>senior legal research analyst</td>\n",
       "      <td>V-Soft</td>\n",
       "      <td>Minneapolis</td>\n",
       "      <td>Eagan, MN</td>\n",
       "      <td>41.0</td>\n",
       "      <td>actual title: legal research analyst - senior ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12968</th>\n",
       "      <td>technician i</td>\n",
       "      <td>Volt Workforce Solutions</td>\n",
       "      <td>Minneapolis</td>\n",
       "      <td>Maplewood, MN</td>\n",
       "      <td>17.0</td>\n",
       "      <td>record data and results in electronic format; ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13195</th>\n",
       "      <td>facilities intern</td>\n",
       "      <td>Natural Resources Defense Council</td>\n",
       "      <td>Washington+City%2CDC</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>15.0</td>\n",
       "      <td>maintain data bases, paper and electronic fili...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13575</th>\n",
       "      <td>payroll support associate at epa</td>\n",
       "      <td>Oak Ridge Associated Universities</td>\n",
       "      <td>Washington+City%2CDC</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>22.0</td>\n",
       "      <td>performing data entry in various ord and agenc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13713</th>\n",
       "      <td>research analyst (vaccines)</td>\n",
       "      <td>Johnson Service Group Inc.</td>\n",
       "      <td>Washington+City%2CDC</td>\n",
       "      <td>Rockville, MD 20850</td>\n",
       "      <td>49.0</td>\n",
       "      <td>provide effort &amp; cost benchmarking &amp; insights ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13892</th>\n",
       "      <td>research analyst with pharma exp.</td>\n",
       "      <td>Johnson Service Group Inc.</td>\n",
       "      <td>Washington+City%2CDC</td>\n",
       "      <td>Rockville, MD 20850</td>\n",
       "      <td>49.0</td>\n",
       "      <td>provide effort &amp; cost benchmarking &amp; insights ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                jobtitle  \\\n",
       "7      entry level – research analyst/editor/content ...   \n",
       "350                                  scientist / chemist   \n",
       "946                                         technician b   \n",
       "2539                                      data scientist   \n",
       "2766   medical technologist ii – microbiology- john h...   \n",
       "2774   medical technologist ii – chemistry- john h. s...   \n",
       "2818   medical technologist iii - john h. stroger hos...   \n",
       "2987                                      data scientist   \n",
       "3041   video machine learning - field position/yard l...   \n",
       "3367             sr associate research operations - 3289   \n",
       "4009   bench scientist i (t-cell, cart, single cell s...   \n",
       "4992           research engineering/ scientist assistant   \n",
       "5004   research engineering/ scientist associate i (e...   \n",
       "5134   engineering scientist associate - research sof...   \n",
       "5135   engineering scientist associate - research sof...   \n",
       "5138   engineering scientist - senior research softwa...   \n",
       "5139   research engineering/ scientist associate i (e...   \n",
       "5142   research engineering/ scientist associate i (e...   \n",
       "5151   social science/humanities research associate v...   \n",
       "5249                                  research associate   \n",
       "5260   digital signal processing/dsp engineer - contract   \n",
       "6232        clinical laboratory scientist i (blood bank)   \n",
       "6303                            data scientist / analyst   \n",
       "7635                           hsc sr research scientist   \n",
       "7750                   senior data scientist - dallas,tx   \n",
       "7952                          corporate research analyst   \n",
       "7971             senior analyst, load research (r17-196)   \n",
       "7995       subject matter expert/artificial intelligence   \n",
       "8057                   office assistant/receptionist sr.   \n",
       "8078                 customer service / research analyst   \n",
       "8588   data analyst oil and gas market research exper...   \n",
       "8705                                data analysis intern   \n",
       "8766     analytical r&d associate scientist 717 (id#014)   \n",
       "8867                              software developer iii   \n",
       "9103                             bench scientist i-44402   \n",
       "9425                                     bench scientist   \n",
       "9503                                        scientist ii   \n",
       "10789                                associate scientist   \n",
       "11043                                associate scientist   \n",
       "11403                          machine learning engineer   \n",
       "11575                  data scientist (contract-to-hire)   \n",
       "11756          administrative assistant - pleasanton, ca   \n",
       "12037                   senior data scientist (contract)   \n",
       "12177                         part time marketing intern   \n",
       "12928           clinical data analyst/scientist/engineer   \n",
       "12930                             legal research analyst   \n",
       "12941                      senior legal research analyst   \n",
       "12968                                       technician i   \n",
       "13195                                  facilities intern   \n",
       "13575                   payroll support associate at epa   \n",
       "13713                        research analyst (vaccines)   \n",
       "13892                  research analyst with pharma exp.   \n",
       "\n",
       "                                                company                  city  \\\n",
       "7                            XG Consultants Group, Inc.         New+York%2CNY   \n",
       "350                                   On-Board Services         New+York%2CNY   \n",
       "946                                 Columbia University         New+York%2CNY   \n",
       "2539                              Workbridge Associates               Chicago   \n",
       "2766              Cook County Health & Hospitals System               Chicago   \n",
       "2774              Cook County Health & Hospitals System               Chicago   \n",
       "2818              Cook County Health & Hospitals System               Chicago   \n",
       "2987                                           PDDN Inc         San+Francisco   \n",
       "3041                                      WingWarp Inc.         San+Francisco   \n",
       "3367                                  Amerit Consulting         San+Francisco   \n",
       "4009                                Aequor Technologies         San+Francisco   \n",
       "4992                      University of Texas at Austin                Austin   \n",
       "5004                      University of Texas at Austin                Austin   \n",
       "5134                      University of Texas at Austin                Austin   \n",
       "5135                      University of Texas at Austin                Austin   \n",
       "5138                      University of Texas at Austin                Austin   \n",
       "5139                      University of Texas at Austin                Austin   \n",
       "5142                      University of Texas at Austin                Austin   \n",
       "5151                      University of Texas at Austin                Austin   \n",
       "5249                                             Unigen               Seattle   \n",
       "5260                                        Vertisystem               Seattle   \n",
       "6232   Los Angeles County Department of Human Resources           Los+Angeles   \n",
       "6303                      Platinum Enterprise Solutions           Los+Angeles   \n",
       "7635                Texas Tech Univ Health Sciences Ctr                Dallas   \n",
       "7750                                      Themesoft Inc                Dallas   \n",
       "7952                                        DiscoverOrg         Portland%2COR   \n",
       "7971                          Portland General Electric         Portland%2COR   \n",
       "7995                        Staff Finders Technical Inc         Portland%2COR   \n",
       "8057                           Arizona State University               Phoenix   \n",
       "8078                                   All About People               Phoenix   \n",
       "8588                                        Adecco: USA               Houston   \n",
       "8705                                           hear.com                 Miami   \n",
       "8766                   The Staffing Resource Group, Inc                 Miami   \n",
       "8867                               Nextgen Technologies                Boston   \n",
       "9103                                              Makro                Boston   \n",
       "9425                                            Fortira                Boston   \n",
       "9503                                 Apex Life Sciences                Boston   \n",
       "10789                              Hunter International             San+Diego   \n",
       "11043                                 On-Board Services             Baltimore   \n",
       "11403                         Consultative Search Group              San+Jose   \n",
       "11575                                Jobspring Partners              San+Jose   \n",
       "11756                                      Q-Chem, Inc.              San+Jose   \n",
       "12037                             Workbridge Associates              San+Jose   \n",
       "12177                                     eComtics, Inc              San+Jose   \n",
       "12928                          Volt Workforce Solutions           Minneapolis   \n",
       "12930                                   Thomson Reuters           Minneapolis   \n",
       "12941                                            V-Soft           Minneapolis   \n",
       "12968                          Volt Workforce Solutions           Minneapolis   \n",
       "13195                 Natural Resources Defense Council  Washington+City%2CDC   \n",
       "13575                 Oak Ridge Associated Universities  Washington+City%2CDC   \n",
       "13713                        Johnson Service Group Inc.  Washington+City%2CDC   \n",
       "13892                        Johnson Service Group Inc.  Washington+City%2CDC   \n",
       "\n",
       "                                             location  salarytxt  \\\n",
       "7                   New York, NY 10017 (Midtown area)       15.0   \n",
       "350                                Franklin Lakes, NJ       40.0   \n",
       "946                                      New York, NY       23.0   \n",
       "2539                                      Chicago, IL       65.0   \n",
       "2766                                      Chicago, IL       24.0   \n",
       "2774                                      Chicago, IL       24.0   \n",
       "2818                                      Chicago, IL       28.0   \n",
       "2987                                    San Mateo, CA       60.0   \n",
       "3041   San Francisco, CA 94158 (South Of Market area)    10000.0   \n",
       "3367                    South San Francisco, CA 94080       34.0   \n",
       "4009                    South San Francisco, CA 94080       38.0   \n",
       "4992                                       Austin, TX     2666.0   \n",
       "5004                                       Austin, TX     2916.0   \n",
       "5134                                       Austin, TX     5000.0   \n",
       "5135                                       Austin, TX     5000.0   \n",
       "5138                                       Austin, TX     6250.0   \n",
       "5139                                       Austin, TX     4166.0   \n",
       "5142                                       Austin, TX     4166.0   \n",
       "5151                                       Austin, TX     5666.0   \n",
       "5249                Seattle, WA 98121 (Belltown area)       20.0   \n",
       "5260                                      Redmond, WA       70.0   \n",
       "6232                                  Los Angeles, CA     7046.0   \n",
       "6303                            Los Angeles, CA 90001       50.0   \n",
       "7635                            Dallas-Fort Worth, TX     4000.0   \n",
       "7750                                       Dallas, TX       50.0   \n",
       "7952                                    Vancouver, WA       15.0   \n",
       "7971               Portland, OR 97204 (Downtown area)     3378.0   \n",
       "7995                                    Hillsboro, OR       70.0   \n",
       "8057                                        Tempe, AZ    19200.0   \n",
       "8078            Phoenix, AZ 85007 (Central City area)       13.0   \n",
       "8588                                       Spring, TX       55.0   \n",
       "8705            Miami, FL 33138 (Upper Eastside area)       12.0   \n",
       "8766                                        Miami, FL       25.0   \n",
       "8867                                    Cambridge, MA      100.0   \n",
       "9103                                      Andover, MA       39.0   \n",
       "9425                                      Andover, MA       24.0   \n",
       "9503                                       Canton, MA       38.0   \n",
       "10789                                   San Diego, CA       28.0   \n",
       "11043                                      Sparks, MD       15.0   \n",
       "11403                                 Santa Clara, CA       85.0   \n",
       "11575              San Jose, CA 95113 (Downtown area)       80.0   \n",
       "11756                            Pleasanton, CA 94588       17.0   \n",
       "12037              San Jose, CA 95113 (Downtown area)      100.0   \n",
       "12177                             Cupertino, CA 95014       12.0   \n",
       "12928                                  Saint Paul, MN       35.0   \n",
       "12930                                       Eagan, MN       23.0   \n",
       "12941                                       Eagan, MN       41.0   \n",
       "12968                                   Maplewood, MN       17.0   \n",
       "13195                                  Washington, DC       15.0   \n",
       "13575                                  Washington, DC       22.0   \n",
       "13713                             Rockville, MD 20850       49.0   \n",
       "13892                             Rockville, MD 20850       49.0   \n",
       "\n",
       "                                                 summary  \n",
       "7      job overview: xg consultants group is looking ...  \n",
       "350    hiring a contract scientist / chemist. experie...  \n",
       "946    experience analyzing large ngs data; the indiv...  \n",
       "2539   a major healthcare corporation that is buildin...  \n",
       "2766   medical technologist (mt), clinical laboratory...  \n",
       "2774   medical technologist (mt), clinical laboratory...  \n",
       "2818   an accredited medical technologist (amt), clin...  \n",
       "2987   data analytics experience do you have:. the te...  \n",
       "3041   we would like to process real time video of a ...  \n",
       "3367   the successful applicant must be able to indep...  \n",
       "4009   job title:  bench scientist i location:  san f...  \n",
       "4992   obtain phenotypic data from biological specime...  \n",
       "5004   purpose to conduct scientific research in dr. ...  \n",
       "5134   two or more years experience with data managem...  \n",
       "5135   two or more years experience with data managem...  \n",
       "5138   experience implementing large data processing ...  \n",
       "5139   software or data carpentry concepts; data fram...  \n",
       "5142   software or data carpentry concepts; collabora...  \n",
       "5151   analyze data using tableau; the survey coordin...  \n",
       "5249   assist scientists in writing technical reports...  \n",
       "5260   work with research scientists, acoustic engine...  \n",
       "6232   enters test results, quality control and impro...  \n",
       "6303   data scientist/analyst6+ months contractplaya ...  \n",
       "7635   assist with all aspects of data collection. co...  \n",
       "7750   senior data scientist *location:. experience w...  \n",
       "7952   verify entered data by reviewing, deleting, or...  \n",
       "7971   maintain large databases and data sets. manipu...  \n",
       "7995   create technical content to support software d...  \n",
       "8057   collects data to maintain such records. enters...  \n",
       "8078   enter data, compiles and compose data reports....  \n",
       "8588   demonstrated experience in creating growth and...  \n",
       "8705   hear.com, the leading innovator in providing m...  \n",
       "8766   analytical research & development associate sc...  \n",
       "8867   the candidate will be working with a team of d...  \n",
       "9103   we are looking for a scientist passionate abou...  \n",
       "9425   junior scientist or lab associate. other exper...  \n",
       "9503   experience with data bases is a plus. employ i...  \n",
       "10789  compile data and records results. analyzes dat...  \n",
       "11043  works with sap enterprise system to enter labo...  \n",
       "11403  data mining and machine learning experience in...  \n",
       "11575  experience with data modeling. a scaling start...  \n",
       "11756  candidate must have earned a high school diplo...  \n",
       "12037  an industry-leading human resources software s...  \n",
       "12177  no data scientist, engineers, operation team a...  \n",
       "12928  under direction, the candidate will process da...  \n",
       "12930  the legal research analyst position is primari...  \n",
       "12941  actual title: legal research analyst - senior ...  \n",
       "12968  record data and results in electronic format; ...  \n",
       "13195  maintain data bases, paper and electronic fili...  \n",
       "13575  performing data entry in various ord and agenc...  \n",
       "13713  provide effort & cost benchmarking & insights ...  \n",
       "13892  provide effort & cost benchmarking & insights ...  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs = jobs.dropna()\n",
    "print jobs.shape\n",
    "\n",
    "jobs.shape\n",
    "jobs[jobs.salarytxt < 20000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 1 0 0]\n",
      " ..., \n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Initialize the \"CountVectorizer\" object, which is scikit-learn's\n",
    "# bag of words tool.  \n",
    "vectorizer = CountVectorizer(analyzer = \"word\",   \\\n",
    "                             tokenizer = None,    \\\n",
    "                             preprocessor = None, \\\n",
    "                             stop_words = 'english',   \\\n",
    "                             max_features = 5000) \n",
    "\n",
    "# fit_transform() does two functions: First, it fits the model\n",
    "# and learns the vocabulary; second, it transforms our training data\n",
    "# into feature vectors. The input to fit_transform should be a list of \n",
    "# strings.\n",
    "train_data_features = vectorizer.fit_transform(jobs.summary)\n",
    "\n",
    "# Numpy arrays are easy to work with, so convert the result to an \n",
    "# array\n",
    "train_data_features = train_data_features.toarray()\n",
    "print train_data_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'10', u'100', u'1099', u'110k', u'12', u'1301', u'130k', u'140k', u'1500', u'160k', u'18', u'300', u'360', u'3yrs', u'40', u'41', u'500', u'60', u'65', u'7905', u'80', u'94080', u'_big', u'_machine', u'ability', u'able', u'absolute', u'academic', u'acceleration', u'acceptable', u'access', u'accomplished', u'accordance', u'according', u'account', u'accounting', u'accounts', u'accredited', u'accumulate', u'accuracy', u'accurate', u'accurately', u'acoustic', u'acquisition', u'act', u'acting', u'action', u'activities', u'actual', u'ada', u'add', u'additional', u'additionally', u'address', u'administration', u'administrative', u'administrator', u'advance', u'advanced', u'advancing', u'advices', u'advisor', u'agency', u'aggregation', u'agile', u'ai', u'aid', u'aim', u'air', u'aircraft', u'algorithms', u'allows', u'alternative', u'alteryx', u'altimetry', u'amended', u'americans', u'aml', u'amounts', u'amt', u'analyses', u'analysis', u'analyst', u'analyst6', u'analysts', u'analytic', u'analytical', u'analytics', u'analyze', u'analyzes', u'analyzing', u'anatomical', u'angeles', u'animal', u'announcement', u'annual', u'answer', u'apache', u'api', u'apkarian', u'applicant', u'applicants', u'application', u'applications', u'applied', u'apply', u'applying', u'appoint', u'appointments', u'appreciation', u'approaches', u'appropriate', u'approved', u'aquatic', u'arcgis', u'architect', u'archive', u'archiving', u'area', u'areas', u'art', u'artificial', u'aspects', u'assay', u'assess', u'assesses', u'assessment', u'assets', u'assigned', u'assigns', u'assist', u'assistance', u'assistant', u'assistants', u'assisting', u'assists', u'associate', u'associates', u'assume', u'atlanta', u'atmospheric', u'attributes', u'audiences', u'aus', u'austin', u'automated', u'available', u'aviation', u'background', u'backup', u'bank', u'base', u'based', u'bases', u'basic', u'basis', u'baxalta', u'beaverton', u'becker', u'behavior', u'behavioral', u'bench', u'benchmark', u'benchmarking', u'bent', u'best', u'better', u'bi', u'big', u'billing', u'biochemical', u'bioinformatics', u'biological', u'biology', u'biomarker', u'biomedical', u'biopsy', u'biostatistics', u'bleeding', u'board', u'bonus', u'brand', u'bricks', u'bring', u'bringing', u'brings', u'broad', u'brokers', u'budget', u'budgets', u'build', u'building', u'bunch', u'bureau', u'bureaus', u'business', u'businesses', u'ca', u'caching', u'caffe', u'calculating', u'calculus', u'california', u'callers', u'camera', u'campaigns', u'cancer', u'candidate', u'candidates', u'cao', u'capability', u'capacity', u'care', u'carpentry', u'cases', u'catalist', u'cdc', u'cds', u'cell', u'center', u'centers', u'certain', u'certification', u'certified', u'certifying', u'cgmps', u'chain', u'chair', u'challenge', u'challenges', u'change', u'changes', u'characterizing', u'checking', u'checks', u'chemist', u'chemistry', u'chemists', u'chicago', u'chief', u'chip', u'chromatography', u'cia', u'cir', u'circulates', u'city', u'class', u'classification', u'classifiers', u'classifying', u'cleaning', u'cleanse', u'cleansing', u'clearance', u'clearinghouse', u'client', u'clients', u'clinical', u'clinically', u'closely', u'cloudera', u'cls', u'cluster', u'cms', u'code', u'coder', u'coding', u'collaborate', u'collaborated', u'collaborates', u'collaborating', u'collaboration', u'collaboratively', u'collaborators', u'collect', u'collected', u'collecting', u'collection', u'collects', u'college', u'com', u'combine', u'comes', u'commercial', u'communicate', u'communication', u'communications', u'companies', u'company', u'compares', u'competency', u'compile', u'compiles', u'compiling', u'completeness', u'completing', u'complex', u'compliance', u'component', u'components', u'compose', u'compri', u'computational', u'compute', u'computer', u'computers', u'computing', u'concepts', u'conclusions', u'conduct', u'conducted', u'conducting', u'conducts', u'confer', u'confidence', u'confidentiality', u'configure', u'confirmation', u'conformity', u'conjointly', u'consequences', u'consistent', u'construct', u'construction', u'consultant', u'consultants', u'consulting', u'consumer', u'consumers', u'contact', u'contacts', u'containing', u'content', u'context', u'continue', u'continuously', u'contract', u'contractor', u'contractplaya', u'contribute', u'contributes', u'control', u'conventional', u'conversant', u'conversion', u'convert', u'coordinate', u'coordinates', u'coordinator', u'coordinators', u'core', u'corporation', u'correlates', u'correlations', u'correspondence', u'cost', u'costar', u'council', u'counterparty', u'country', u'cover', u'craft', u'create', u'created', u'creating', u'creation', u'creative', u'creatives', u'credit', u'crime', u'criminal', u'cro', u'crucial', u'cryo', u'culver', u'curation', u'current', u'currently', u'custom', u'customer', u'customers', u'customized', u'cutting', u'cyber', u'dashboard', u'dashboards', u'data', u'database', u'databases', u'datacenter', u'dataset', u'datasets', u'date', u'deadlines', u'decision', u'decisions', u'dedicated', u'dedication', u'deep', u'defense', u'define', u'defining', u'definitions', u'degree', u'deleting', u'deliver', u'delivering', u'delivers', u'demographic', u'demography', u'demonstrate', u'demonstrated', u'deparment', u'department', u'departments', u'dependent', u'depending', u'deploy', u'deployment', u'depth', u'descriptionour', u'design', u'designers', u'designing', u'designs', u'desktop', u'detailed', u'detailing', u'detect', u'detection', u'determination', u'determine', u'determining', u'develop', u'developed', u'developers', u'developing', u'development', u'develops', u'devices', u'dictionary', u'different', u'differential', u'digital', u'diligence', u'diploma', u'direct', u'direction', u'directly', u'director', u'disclosure', u'discovery', u'discrepancies', u'discrete', u'discuss', u'disease', u'display', u'dissemination', u'distributed', u'distribution', u'dive', u'diverse', u'division', u'dl', u'doc', u'docker', u'doctoral', u'doctors', u'document', u'documentation', u'documents', u'domain', u'doors', u'dosing', u'dr', u'drafting', u'draw', u'drinking', u'drive', u'driven', u'drives', u'drug', u'drugs', u'duration', u'duties', u'duty', u'dynamic', u'dynamics', u'eagan', u'early', u'earned', u'ecomtics', u'econometric', u'ecosystem', u'edge', u'edit', u'education', u'educational', u'effective', u'effectively', u'efficiency', u'efficient', u'efficiently', u'effluent', u'effort', u'elasticsearch', u'electron', u'electronic', u'elements', u'eligible', u'elk', u'elucidation', u'em', u'emc', u'emerging', u'emory', u'employ', u'employees', u'employment', u'enable', u'end', u'energy', u'engaged', u'engagements', u'engages', u'engaging', u'engineer', u'engineering', u'engineers', u'enhance', u'enhancements', u'enhances', u'ensure', u'ensures', u'enter', u'entered', u'entering', u'enterprise', u'enterprises', u'enters', u'enthusiastic', u'entry', u'envelopment', u'environment', u'environmental', u'epa', u'epic', u'epidemiologic', u'epidemiological', u'epidemiology', u'equations', u'equipment', u'errors', u'especially', u'essential', u'establish', u'estate', u'estimations', u'ethical', u'etl', u'etrack', u'evaluate', u'evaluates', u'evaluating', u'evaluation', u'evaluations', u'evenings', u'eventual', u'evidence', u'examination', u'examine', u'excel', u'excellent', u'exciting', u'exclusive', u'execute', u'execution', u'executive', u'existing', u'expected', u'experience', u'experienced', u'experiences', u'experiment', u'experimental', u'experimentation', u'experiments', u'expert', u'expertise', u'experts', u'exploit', u'exploration', u'exploratory', u'explore', u'exponentially', u'export', u'exposure', u'express', u'expression', u'extends', u'extensive', u'external', u'extract', u'extracting', u'extraction', u'extracts', u'extremely', u'facilitate', u'facility', u'facing', u'faculty', u'familiarity', u'familiarization', u'fast', u'fcs', u'field', u'fielding', u'fields', u'figure', u'figures', u'files', u'filing', u'final', u'financial', u'findings', u'fine', u'firm', u'fix', u'flow', u'flowjo', u'focus', u'follow', u'following', u'follows', u'food', u'football', u'forecasting', u'forensic', u'form', u'format', u'formation', u'formats', u'forms', u'formulating', u'fortune', u'foundations', u'founder', u'fpga', u'framework', u'frameworks', u'francisco', u'fraud', u'fremont', u'frequency', u'frontline', u'function', u'functional', u'functions', u'fund', u'funded', u'funding', u'fuse', u'future', u'ga', u'gain', u'game', u'gather', u'gathering', u'gavin', u'gen', u'gene', u'general', u'generate', u'generates', u'generating', u'generation', u'genetically', u'genomic', u'geo', u'geographic', u'geographical', u'geology', u'geospatial', u'getting', u'global', u'globally', u'gnss', u'goals', u'good', u'governance', u'graduate', u'grant', u'grantplan', u'graphic', u'graphical', u'graphing', u'graphpad', u'graphs', u'grids', u'ground', u'grounded', u'group', u'groups', u'grow', u'growing', u'growth', u'guidance', u'guidelines', u'hadoop', u'half', u'handle', u'handling', u'handwritten', u'hardware', u'hazard', u'hazardous', u'hbase', u'hdfs', u'head', u'health', u'healthcare', u'hear', u'hearing', u'hello', u'help', u'helpful', u'helping', u'helps', u'hidden', u'high', u'higher', u'hire', u'hiring', u'historical', u'hitachi', u'hive', u'hmc', u'holders', u'home', u'hopkins', u'hospital', u'hosted', u'hourly', u'hours', u'house', u'hplc', u'hr', u'htn', u'huge', u'human', u'humans', u'hunt', u'hw', u'hybrid', u'hydrologic', u'hyperion', u'hyperscale', u'hypotheses', u'hypothesis', u'id', u'ideal', u'ideally', u'ideas', u'identify', u'iii', u'image', u'images', u'imaging', u'immediate', u'imminent', u'immunotherapies', u'impala', u'imperfect', u'implantation', u'implement', u'implementation', u'implementing', u'implements', u'import', u'improve', u'improvement', u'incentives', u'include', u'included', u'includes', u'including', u'incoming', u'incomplete', u'inconsistent', u'incorporation', u'increase', u'incumbent', u'independently', u'indexing', u'individual', u'industry', u'inferences', u'inform', u'informatics', u'information', u'informed', u'infrastructure', u'initial', u'initiative', u'initiatives', u'innovating', u'innovation', u'innovative', u'innovator', u'insight', u'insights', u'inspect', u'instructed', u'instructor', u'instrumental', u'instrumentation', u'instruments', u'insurance', u'integral', u'integrated', u'integration', u'integrity', u'intel', u'intelligence', u'interact', u'interaction', u'interactive', u'interested', u'interface', u'interfacing', u'intergrity', u'internal', u'international', u'internet', u'interns', u'internship', u'interpersonal', u'interpret', u'interpretation', u'interpreting', u'interrogate', u'introduce', u'inventory', u'investigation', u'investigator', u'investigators', u'investment', u'investments', u'involve', u'involved', u'involving', u'ipeds', u'isolate', u'isotope', u'issued', u'issues', u'jails', u'java', u'javascript', u'job', u'johns', u'johnson', u'join', u'joining', u'joins', u'journal', u'junior', u'jupyter', u'justifications', u'kafka', u'keeping', u'kenneth', u'key', u'keyboard', u'know', u'knowledge', u'known', u'kyc', u'lab', u'laboratory', u'lakes', u'land', u'language', u'languages', u'large', u'latency', u'law', u'lay', u'lead', u'leader', u'leadership', u'leading', u'learing', u'learn', u'learning', u'legal', u'level', u'leverage', u'leveraging', u'liason', u'liberty', u'librarian', u'libraries', u'license', u'life', u'like', u'limit', u'limited', u'line', u'liquid', u'literature', u'lives', u'll', u'load', u'loading', u'located', u'location', u'logical', u'logstash', u'longitudinal', u'looking', u'loop', u'los', u'low', u'machine', u'maintain', u'maintaining', u'maintains', u'maintenance', u'major', u'majority', u'make', u'makers', u'makes', u'making', u'manage', u'management', u'manager', u'managers', u'manages', u'managing', u'manipulate', u'manipulating', u'manipulation', u'manner', u'manuals', u'manuscript', u'map', u'maplewood', u'mapreduce', u'maps', u'market', u'marketing', u'markets', u'mass', u'massive', u'master', u'masters', u'material', u'materials', u'mathematical', u'mathematics', u'matlab', u'maven', u'max', u'mch', u'measurement', u'medcillary', u'media', u'medical', u'medicine', u'meet', u'meetings', u'member', u'members', u'mentor', u'message', u'metadata', u'methodologic', u'methodological', u'methodologies', u'methodology', u'methods', u'metrics', u'metropolitan', u'microdata', u'microscope', u'microscopy', u'microsoft', u'mid', u'middlewares', u'million', u'minimal', u'mining', u'missing', u'mission', u'mix', u'ml', u'mn', u'mode', u'model', u'modeler', u'modeling', u'models', u'moderately', u'modern', u'modified', u'modifying', u'molecule', u'monitor', u'monitoring', u'month', u'months', u'movement', u'mpd', u'ms', u'mt', u'multiple', u'naloxone', u'names', u'nation', u'national', u'nationally', u'natural', u'navigate', u'navigator', u'near', u'necessary', u'need', u'needed', u'needs', u'netapp', u'networked', u'networks', u'neural', u'new', u'ngs', u'nice', u'nifi', u'nih', u'nlp', u'noise', u'non', u'normal', u'north', u'notebook', u'novel', u'nrdc', u'numbers', u'numerical', u'nyc', u'oakland', u'objective', u'objectives', u'observations', u'observe', u'obtain', u'obtained', u'octri', u'od', u'ofe', u'offered', u'offers', u'office', u'offices', u'oncogenomic', u'online', u'open', u'opencv', u'opening', u'operation', u'operational', u'operations', u'opportunities', u'opportunity', u'optical', u'optimize', u'optimized', u'optimizing', u'options', u'oral', u'orbit', u'ord', u'order', u'organization', u'organize', u'organizing', u'outcome', u'outcomes', u'outlook', u'overdose', u'oversee', u'overview', u'pa', u'paced', u'package', u'packages', u'paid', u'paper', u'participate', u'participates', u'particularly', u'partner', u'partnership', u'pass', u'passionate', u'pathologists', u'pathology', u'patient', u'patients', u'patrol', u'patterns', u'pay', u'payable', u'payments', u'payroll', u'peer', u'pentaho', u'perform', u'performance', u'performant', u'performing', u'performs', u'perl', u'perm', u'permanent', u'permit', u'person', u'personal', u'pertaining', u'ph', u'phd', u'phenotypic', u'philadelphia', u'phosphorus', u'physical', u'physician', u'pig', u'pipelines', u'place', u'plan', u'planners', u'planning', u'plans', u'plant', u'plate', u'platform', u'platforms', u'plotting', u'plus', u'point', u'police', u'policies', u'policy', u'portal', u'portfolio', u'position', u'positions', u'possess', u'post', u'postings', u'power', u'powerpoint', u'ppc', u'practical', u'practice', u'practices', u'pre', u'predict', u'predicting', u'prediction', u'predictions', u'predictive', u'predictors', u'preferred', u'preparation', u'prepare', u'prepares', u'preparing', u'prescribes', u'prescriptive', u'present', u'presentations', u'presenting', u'prevention', u'previous', u'pricing', u'primarily', u'primary', u'principal', u'principals', u'principles', u'prior', u'priorities', u'prioritize', u'prism', u'probability', u'problem', u'problems', u'procedure', u'procedures', u'process', u'processes', u'processing', u'produce', u'product', u'products', u'professional', u'professionals', u'proficiency', u'proficient', u'profiles', u'program', u'programmatic', u'programmers', u'programming', u'programs', u'progression', u'project', u'projects', u'prominent', u'promote', u'proper', u'properties', u'proposals', u'propose', u'proprietary', u'prosecuting', u'protecting', u'protection', u'protein', u'proteomics', u'protocol', u'protocols', u'prototype', u'proven', u'provide', u'provider', u'provides', u'providing', u'psychiatry', u'psychoacoustics', u'public', u'publications', u'purification', u'purpose', u'purposes', u'python', u'qa', u'qm', u'qualifications', u'qualified', u'qualitative', u'quality', u'quantitative', u'quarterly', u'queries', u'querying', u'questions', u'queuing', u'quickly', u'radio', u'radiogenic', u'radiologist', u'range', u'ranges', u'rapid', u'rapidly', u'rate', u'rates', u'ratings', u'rc4wd', u'reader', u'reading', u'real', u'realistic', u'receive', u'receiving', u'recent', u'recognition', u'recognizes', u'recommendations', u'record', u'recorded', u'recording', u'records', u'recreational', u'reduction', u'regarding', u'regular', u'regularly', u'regulatory', u'related', u'relational', u'relationships', u'relative', u'release', u'releasing', u'relevant', u'remittance', u'remote', u'remotely', u'renewal', u'renowned', u'replacement', u'report', u'reported', u'reporting', u'reports', u'request', u'requests', u'require', u'required', u'requirement', u'requirements', u'research', u'researcher', u'researchers', u'researches', u'researching', u'resection', u'resolve', u'resource', u'resources', u'responding', u'responsibilities', u'responsibility', u'responsible', u'resulting', u'results', u'retrieval', u'retrieve', u'reversal', u'review', u'reviewed', u'reviewing', u'reviews', u'revised', u'revolutionary', u'rich', u'right', u'risk', u'risks', u'river', u'rna', u'role', u'roles', u'routine', u'rows', u'rsa', u'rstp', u'ruby', u'runs', u'sacramento', u'safety', u'said', u'salary', u'sales', u'sample', u'samples', u'sampling', u'san', u'sap', u'sas', u'satellite', u'savvy', u'scala', u'scale', u'scaling', u'scanner', u'scanning', u'sccc', u'scheduling', u'schemas', u'school', u'sci', u'science', u'sciences', u'scientific', u'scientist', u'scientists', u'scikit', u'scipy', u'screening', u'scripting', u'scripts', u'sdlc', u'search', u'searches', u'seasoned', u'seattle', u'secondary', u'section', u'sections', u'security', u'seed', u'seekers', u'seeking', u'seeks', u'segmentation', u'segments', u'selected', u'selection', u'send', u'senior', u'sensor', u'sequence', u'sequencing', u'series', u'serotype', u'servers', u'serves', u'service', u'services', u'serving', u'set', u'sets', u'setting', u'settlement', u'sfe', u'shall', u'shape', u'sharing', u'sharp', u'shire', u'shoots', u'showing', u'shows', u'signal', u'significance', u'significant', u'similar', u'single', u'site', u'sitelock', u'sites', u'skill', u'skilled', u'skills', u'small', u'smart', u'social', u'software', u'soil', u'solid', u'solr', u'solution', u'solutions', u'solve', u'solving', u'sought', u'sound', u'source', u'sources', u'sourcing', u'sp', u'space', u'sparcs', u'spark', u'special', u'specialist', u'specialists', u'specializing', u'specific', u'specifications', u'specified', u'specimens', u'spectrometry', u'spectrum', u'spend', u'sponsor', u'sponsored', u'spreadsheet', u'spreadsheets', u'sql', u'sr', u'stability', u'stable', u'stack', u'staff', u'stage', u'stake', u'standard', u'standardize', u'standards', u'start', u'startup', u'state', u'statewide', u'statistical', u'statistician', u'statisticians', u'statistics', u'stats', u'stealth', u'stem', u'step', u'steps', u'storage', u'stores', u'stories', u'strategies', u'strategists', u'strategy', u'stream', u'streaming', u'strict', u'strides', u'strong', u'strongly', u'structure', u'structures', u'student', u'students', u'studies', u'study', u'submission', u'submissions', u'submitted', u'subordinate', u'subsequent', u'substantive', u'substitute', u'substituted', u'succeed', u'success', u'successful', u'suite', u'summarize', u'summarizing', u'summary', u'supervising', u'supervision', u'supervisor', u'suppliers', u'supply', u'support', u'supporting', u'supports', u'sure', u'surgeons', u'surgical', u'surveillance', u'survey', u'survival', u'svt', u'sw', u'swim', u'synthesis', u'systems', u'tableau', u'talented', u'talking', u'target', u'task', u'tasked', u'tasks', u'tcga', u'team', u'teams', u'tecan', u'tech', u'technical', u'technician', u'technicians', u'techniques', u'technologies', u'technologist', u'technologists', u'technology', u'tekhiring', u'tensoeflow', u'tensorflow', u'terabytes', u'test', u'testing', u'texas', u'theano', u'theory', u'therapy', u'threat', u'throughput', u'tier', u'time', u'timely', u'titer', u'title', u'tools', u'toolset', u'torch', u'toxicology', u'track', u'tracking', u'traders', u'traditional', u'trainee', u'trainees', u'training', u'transactions', u'transfer', u'transform', u'transformation', u'treatments', u'trends', u'triage', u'trouble', u'troubleshooting', u'trust', u'ts', u'tumor', u'tuning', u'tx', u'type', u'types', u'typically', u'typing', u'ub', u'ultra', u'unbridled', u'understand', u'understanding', u'unexpected', u'university', u'unless', u'unmanned', u'unorthodox', u'unparalleled', u'unpleasant', u'unstructured', u'update', u'updating', u'uplc', u'upper', u'usage', u'use', u'used', u'user', u'uses', u'using', u'utilization', u'utilize', u'utilized', u'utilizes', u'utilizing', u'uw', u'uwmc', u'vaccine', u'validate', u'validation', u'validity', u'value', u'variable', u'variety', u'various', u'vast', u'veera', u'verify', u'vertical', u'victory', u'video', u'view', u'views', u'virtual', u'visible', u'vision', u'visit', u'vista', u'visualization', u'visualizations', u'visualize', u'vital', u'vivo', u'vlbi', u'vmo', u'voice', u'volt', u'volume', u'w2', u'wa', u'warehouse', u'warehoused', u'warehouses', u'warehousing', u'washington', u'waste', u'water', u'waters', u'way', u'ways', u'wbs', u'wealth', u'web', u'website', u'websites', u'west', u'westlaw', u'whilst', u'win', u'word', u'work', u'workflow', u'workflows', u'workforce', u'working', u'works', u'world', u'write', u'writing', u'written', u'xg', u'yard', u'yards', u'year', u'years', u'york', u'yr', u'zeppelin']\n"
     ]
    }
   ],
   "source": [
    "vocab = vectorizer.get_feature_names()\n",
    "\n",
    "print vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1717"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding Job Titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'Senior Data Scientist',\n",
       " u'Research Assistant - Bioelectronic Medicine',\n",
       " u'Data Scientist',\n",
       " u'Data Scientist',\n",
       " u'Data Scientist',\n",
       " u'Data Scientist',\n",
       " u'Data Scientist',\n",
       " u'Data Scientist',\n",
       " u'Team Lead Data Scientist - Predictive Analytics',\n",
       " u'Data Scientist',\n",
       " u'Data Scientist',\n",
       " u'Data Analyst',\n",
       " u'Software Engineer / Research Scientist - Machine Learning Team',\n",
       " u'Lead Data Warehouse Developer/Modeler',\n",
       " u'Quantitative Analyst']"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_jt(page):\n",
    "    jt = []\n",
    "    for i in page.find_all(name = 'div', attrs = {'class':'row'}):\n",
    "        for a in i.find_all(name = 'a', attrs = {'data-tn-element':'jobTitle'}):\n",
    "            jt.append(a[\"title\"])\n",
    "    return(jt)\n",
    "jt = get_jt(page)\n",
    "jt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding Company Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'HumanEdge',\n",
       " u'NYU School of Medicine',\n",
       " u'Knewton',\n",
       " u'adMarketplace',\n",
       " u'Vettery',\n",
       " u'HelloFresh',\n",
       " u'RangTech',\n",
       " u'Grubhub',\n",
       " u'Fareportal Inc.',\n",
       " u'Lockheed Martin',\n",
       " u'POLICE DEPARTMENT',\n",
       " u'Indellient',\n",
       " u'1010data',\n",
       " u'Bloomberg',\n",
       " u'Indica Labs']"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_comps(page): \n",
    "    companies = []\n",
    "    for div in soup.find_all(name='div', attrs={'class':'row'}):\n",
    "        company = div.find_all(name='span', attrs={'class':'company'})\n",
    "        if len(company) > 0:\n",
    "            for b in company:\n",
    "                companies.append(b.text.strip())\n",
    "#         else:\n",
    "#             sec_try = div.find_all(name='span', attrs={'class':'result-link-source'})\n",
    "#         for span in sec_try:\n",
    "#             companies.append(span.text.strip())\n",
    "    return(companies)\n",
    "cn = get_comps(page)\n",
    "cn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if len(company) > 0:\n",
    "#             for b in company:\n",
    "#                 cn.append(b.text.strip())\n",
    "#         else:\n",
    "#             sec_try = i.find_all(name= 'span', attrs={'class':'result-link-source'})\n",
    "#         for span in sec_try:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'New York, NY',\n",
       " u'Manhasset, NY 11030',\n",
       " u'New York, NY',\n",
       " u'New York, NY',\n",
       " u'New York, NY',\n",
       " u'New York, NY',\n",
       " u'New York, NY',\n",
       " u'New York, NY',\n",
       " u'New York, NY',\n",
       " u'New York, NY 10020 (Midtown area)',\n",
       " u'Owego, NY 13827',\n",
       " u'New York, NY',\n",
       " u'New York, NY',\n",
       " u'New York, NY',\n",
       " u'New York, NY 10016']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_locs(soup): \n",
    "    locations = []\n",
    "    spans = page.findAll('span', attrs={'class': 'location'})\n",
    "    for span in spans:\n",
    "        locations.append(span.text)\n",
    "    return(locations)\n",
    "get_locs(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'$150,000 - $250,000 a year',\n",
       " 'NA',\n",
       " 'NA',\n",
       " 'NA',\n",
       " 'NA',\n",
       " 'NA',\n",
       " 'NA',\n",
       " 'NA',\n",
       " 'NA',\n",
       " 'NA',\n",
       " 'NA',\n",
       " 'NA',\n",
       " 'NA',\n",
       " 'NA',\n",
       " u'$125,000 - $175,000 a year']"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_salary(page): \n",
    "    salaries = []\n",
    "    for div in page.find_all(name='div', attrs={'class':'row'}):\n",
    "        try:\n",
    "            salaries.append(div.find('nobr').text)\n",
    "        except:\n",
    "            try:\n",
    "                div_two = div.find(name='div', attrs={'class':'sjcl'})\n",
    "                div_three = div_two.find('div')\n",
    "                salaries.append(div_three.text.strip())\n",
    "            except:\n",
    "                salaries.append('NA')\n",
    "    return(salaries)\n",
    "js = get_salary(page)\n",
    "js"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Job Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'list'>\n",
      "<type 'list'>\n",
      "<type 'list'>\n"
     ]
    }
   ],
   "source": [
    "print type(jt)\n",
    "print type(cn)\n",
    "print type(js)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>HumanEdge</td>\n",
       "      <td>$150,000 - $250,000 a year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Research Assistant - Bioelectronic Medicine</td>\n",
       "      <td>NYU School of Medicine</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Knewton</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>adMarketplace</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Vettery</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>HelloFresh</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>RangTech</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Grubhub</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Team Lead Data Scientist - Predictive Analytics</td>\n",
       "      <td>Fareportal Inc.</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Lockheed Martin</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>POLICE DEPARTMENT</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Indellient</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Software Engineer / Research Scientist - Machi...</td>\n",
       "      <td>1010data</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Lead Data Warehouse Developer/Modeler</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Quantitative Analyst</td>\n",
       "      <td>Indica Labs</td>\n",
       "      <td>$125,000 - $175,000 a year</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title                 company  \\\n",
       "0                               Senior Data Scientist               HumanEdge   \n",
       "1         Research Assistant - Bioelectronic Medicine  NYU School of Medicine   \n",
       "2                                      Data Scientist                 Knewton   \n",
       "3                                      Data Scientist           adMarketplace   \n",
       "4                                      Data Scientist                 Vettery   \n",
       "5                                      Data Scientist              HelloFresh   \n",
       "6                                      Data Scientist                RangTech   \n",
       "7                                      Data Scientist                 Grubhub   \n",
       "8     Team Lead Data Scientist - Predictive Analytics         Fareportal Inc.   \n",
       "9                                      Data Scientist         Lockheed Martin   \n",
       "10                                     Data Scientist       POLICE DEPARTMENT   \n",
       "11                                       Data Analyst              Indellient   \n",
       "12  Software Engineer / Research Scientist - Machi...                1010data   \n",
       "13              Lead Data Warehouse Developer/Modeler               Bloomberg   \n",
       "14                               Quantitative Analyst             Indica Labs   \n",
       "\n",
       "                        salary  \n",
       "0   $150,000 - $250,000 a year  \n",
       "1                           NA  \n",
       "2                           NA  \n",
       "3                           NA  \n",
       "4                           NA  \n",
       "5                           NA  \n",
       "6                           NA  \n",
       "7                           NA  \n",
       "8                           NA  \n",
       "9                           NA  \n",
       "10                          NA  \n",
       "11                          NA  \n",
       "12                          NA  \n",
       "13                          NA  \n",
       "14  $125,000 - $175,000 a year  "
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs = []\n",
    "\n",
    "jobs = pd.DataFrame({'title':jt,\n",
    "                     'company':cn,\n",
    "                     'salary':js}, columns= ['title','company','salary'])\n",
    "jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code from Michael Salmon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot set a frame with no defined columns",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-8c1059a472ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m                 \u001b[0mjob_post\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Nothing_found'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;31m#appending list of job post info to dataframe at index num\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0msample_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjob_post\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;31m#saving sample_df as a local csv file — define your own local path to save contents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0msample_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'C://Users/baurjansafi/Downloands/df.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/baurjansafi/anaconda/lib/python2.7/site-packages/pandas/core/indexing.pyc\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_setitem_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_has_valid_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/baurjansafi/anaconda/lib/python2.7/site-packages/pandas/core/indexing.pyc\u001b[0m in \u001b[0;36m_setitem_with_indexer\u001b[0;34m(self, indexer, value)\u001b[0m\n\u001b[1;32m    401\u001b[0m                     \u001b[0;31m# no columns and scalar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m                         raise ValueError(\"cannot set a frame with no defined \"\n\u001b[0m\u001b[1;32m    404\u001b[0m                                          \"columns\")\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot set a frame with no defined columns"
     ]
    }
   ],
   "source": [
    "## YOUR CODE HERE\n",
    "#scraping code:\n",
    "city_set = ['New York']\n",
    "start = '10'\n",
    "max_results_per_city = 10\n",
    "sample_df = pd.DataFrame()\n",
    "\n",
    "\n",
    "for city in city_set:\n",
    "  for start in range(0, max_results_per_city, 10):\n",
    "    page = requests.get('http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l=' \n",
    "                        + str(city) + '&start=' + str(start))\n",
    "    time.sleep(1)  #ensuring at least 1 second between page grabs\n",
    "    soup = BeautifulSoup(page.text, 'lxml', from_encoding='utf-8')\n",
    "    for div in soup.find_all(name='div', attrs={'class':'row'}): \n",
    "    #specifying row num for index of job posting in dataframe\n",
    "        num = (len(sample_df) + 1) \n",
    "    #creating an empty list to hold the data for each posting\n",
    "        job_post = [] \n",
    "    #append city name\n",
    "        job_post.append(city) \n",
    "    #grabbing job title\n",
    "        for a in div.find_all(name='a', attrs={'data-tn-element':'jobTitle'}):\n",
    "            job_post.append(a['title']) \n",
    "    #grabbing company name\n",
    "        company = div.find_all(name='span', attrs={'class':'company'}) \n",
    "        if len(company) > 0: \n",
    "            for b in company:\n",
    "                job_post.append(b.text.strip()) \n",
    "        else: \n",
    "            sec_try = div.find_all(name='span', attrs={'class':'result-link-source'})\n",
    "            for span in sec_try:\n",
    "                job_post.append(span.text) \n",
    "    #grabbing location name\n",
    "        c = div.findAll('span', attrs={'class': 'location'}) \n",
    "        for span in c: \n",
    "            job_post.append(span.text) \n",
    "    #grabbing summary text\n",
    "        d = div.findAll('span', attrs={'class': 'summary'}) \n",
    "        for span in d:\n",
    "            job_post.append(span.text.strip()) \n",
    "    #grabbing salary\n",
    "        try:\n",
    "            job_post.append(div.find('nobr').text) \n",
    "        except:\n",
    "            try:\n",
    "                div_two = div.find(name='div', attrs={'class':'sjcl'}) \n",
    "                div_three = div_two.find('div') \n",
    "                job_post.append(div_three.text.strip())\n",
    "            except:\n",
    "                job_post.append('Nothing_found') \n",
    "    #appending list of job post info to dataframe at index num\n",
    "            sample_df.loc[num] = job_post\n",
    "#saving sample_df as a local csv file — define your own local path to save contents \n",
    "sample_df.to_csv('C://Users/baurjansafi/Downloands/df.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at one result more closely. A single result looks like\n",
    "```JSON\n",
    "<div class=\" row result\" data-jk=\"2480d203f7e97210\" data-tn-component=\"organicJob\" id=\"p_2480d203f7e97210\" itemscope=\"\" itemtype=\"http://schema.org/JobPosting\">\n",
    "<h2 class=\"jobtitle\" id=\"jl_2480d203f7e97210\">\n",
    "<a class=\"turnstileLink\" data-tn-element=\"jobTitle\" onmousedown=\"return rclk(this,jobmap[0],1);\" rel=\"nofollow\" target=\"_blank\" title=\"AVP/Quantitative Analyst\">AVP/Quantitative Analyst</a>\n",
    "</h2>\n",
    "<span class=\"company\" itemprop=\"hiringOrganization\" itemtype=\"http://schema.org/Organization\">\n",
    "<span itemprop=\"name\">\n",
    "<a href=\"/cmp/Alliancebernstein?from=SERP&campaignid=serp-linkcompanyname&fromjk=2480d203f7e97210&jcid=b374f2a780e04789\" target=\"_blank\">\n",
    "    AllianceBernstein</a></span>\n",
    "</span>\n",
    "<tr>\n",
    "<td class=\"snip\">\n",
    "<nobr>$117,500 - $127,500 a year</nobr>\n",
    "<div>\n",
    "<span class=\"summary\" itemprop=\"description\">\n",
    "C onduct quantitative and statistical research as well as portfolio management for various investment portfolios. Collaborate with Quantitative Analysts and</span>\n",
    "</div>\n",
    "</div>\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "</div>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this has some more verbose elements removed, we can see that there is some structure to the above:\n",
    "- The salary is available in a nobr element inside of a td element with class='snip.\n",
    "- The title of a job is in a link with class set to jobtitle and a data-tn-element=\"jobTitle.\n",
    "- The location is set in a span with class='location'.\n",
    "- The company is set in a span with class='company'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write 4 functions to extract these items (one function for each): location, company, job title, and salary.¶\n",
    "Example\n",
    "```python\n",
    "def extract_location_from_result(result):\n",
    "    return result.find ...\n",
    "```\n",
    "\n",
    "##### - Make sure these functions are robust and can handle cases where the data/field may not be available.\n",
    ">- Remember to check if a field is empty or None for attempting to call methods on it\n",
    ">- Remember to use try/except if you anticipate errors.\n",
    "\n",
    "- **Test** the functions on the results above and simple examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to scale up our scraping, we need to accumulate more results. We can do this by examining the URL above.\n",
    "- \"http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l=New+York&start=10\"\n",
    "\n",
    "There are two query parameters here we can alter to collect more results, the l=New+York and the start=10. The first controls the location of the results (so we can try a different city). The second controls where in the results to start and gives 10 results (thus, we can keep incrementing by 10 to go further in the list).\n",
    "##### Complete the following code to collect results from multiple cities and starting points.\n",
    "- Enter your city below to add it to the search\n",
    "- Remember to convert your salary to U.S. Dollars to match the other cities if the currency is different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "YOUR_CITY = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url_template = \"http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l={}&start={}\"\n",
    "max_results_per_city = 100 # Set this to a high-value (5000) to generate more results. \n",
    "# Crawling more results, will also take much longer. First test your code on a small number of results and then expand.\n",
    "\n",
    "results = []\n",
    "\n",
    "for city in set(['New+York', 'Chicago', 'San+Francisco', 'Austin', 'Seattle', \n",
    "    'Los+Angeles', 'Philadelphia', 'Atlanta', 'Dallas', 'Pittsburgh', \n",
    "    'Portland', 'Phoenix', 'Denver', 'Houston', 'Miami', YOUR_CITY]):\n",
    "    for start in range(0, max_results_per_city, 10):\n",
    "        # Grab the results from the request (as above)\n",
    "        # Append to the full set of results\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "20339c09-5032-4e27-91be-286e9b46cd13"
   },
   "source": [
    "#### Use the functions you wrote above to parse out the 4 fields - location, title, company and salary. Create a dataframe from the results with those 4 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "6e259594-1c52-436b-ab9e-527e071941c1"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "ff98ce64-78a7-441f-a675-63464e32c834"
   },
   "source": [
    "Lastly, we need to clean up salary data. \n",
    "\n",
    "1. Only a small number of the scraped results have salary information - only these will be used for modeling.\n",
    "1. Some of the salaries are not yearly but hourly or weekly, these will not be useful to us for now\n",
    "1. Some of the entries may be duplicated\n",
    "1. The salaries are given as text and usually with ranges.\n",
    "\n",
    "#### Find the entries with annual salary entries, by filtering the entries without salaries or salaries that are not yearly (filter those that refer to hour or week). Also, remove duplicate entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "58533e57-f86b-494a-b841-e7b59c6229c6"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "7d4bc860-b214-4f75-9cd0-b234830b1ec2"
   },
   "source": [
    "#### Write a function that takes a salary string and converts it to a number, averaging a salary range if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "a0f701e0-80bd-40ba-9101-4535860c0968"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "43e71edd-210e-42b1-9336-70a931f048af"
   },
   "source": [
    "### Save your results as a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "783fd153-28ac-47ab-bfca-27e7c1de95b4"
   },
   "outputs": [],
   "source": [
    "# Export to csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "04563b69-f7b6-466f-9d65-fc62c9ddee6a"
   },
   "source": [
    "## Predicting salaries using Random Forests + Another Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "243e949e-2742-40af-872e-fec475fd306c"
   },
   "source": [
    "#### Load in the the data of scraped salaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "588f9845-6143-4bcc-bfd1-85d45b79303d"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "c7631f51-07f2-4c79-a093-3e9bc7849a48"
   },
   "source": [
    "#### We want to predict a binary variable - whether the salary was low or high. Compute the median salary and create a new binary variable that is true when the salary is high (above the median)\n",
    "\n",
    "We could also perform Linear Regression (or any regression) to predict the salary value here. Instead, we are going to convert this into a _binary_ classification problem, by predicting two classes, HIGH vs LOW salary.\n",
    "\n",
    "While performing regression may be better, performing classification may help remove some of the noise of the extreme salaries. We don't _have_ to choose the `median` as the splitting point - we could also split on the 75th percentile or any other reasonable breaking point.\n",
    "\n",
    "In fact, the ideal scenario may be to predict many levels of salaries, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "c20d2498-151c-44c3-a453-3a333c79a0ac"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "a7afb2c0-d41e-4779-8216-91cd8dd4473f"
   },
   "source": [
    "#### Thought experiment: What is the baseline accuracy for this model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "87a17d3d-b7f4-4747-9f75-f9af1d18a174"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "4fb29de2-5b98-474c-a4ad-5170b72b9aea"
   },
   "source": [
    "#### Create a Random Forest model to predict High/Low salary using Sklearn. Start by ONLY using the location as a feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "ddbc6159-6854-4ca7-857f-bfecdaf6d9c2"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "0ef04f32-419c-4bf2-baf7-48201f03df89"
   },
   "source": [
    "#### Create a few new variables in your dataframe to represent interesting features of a job title.\n",
    "- For example, create a feature that represents whether 'Senior' is in the title or whether 'Manager' is in the title. \n",
    "- Then build a new Random Forest with these features. Do they add any value?\n",
    "- After creating these variables, use count-vectorizer to create features based on the words in the job titles.\n",
    "- Build a new random forest model with location and these new features included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "9367beff-72ba-4768-a0ba-a50b335de61d"
   },
   "source": [
    "#### Use cross-validation in scikit-learn to evaluate the model above. \n",
    "- Evaluate the accuracy of the model, as well as any other metrics you feel are appropriate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "269b9e7c-60b5-4a06-8255-881d7395bc1b"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Repeat the model-building process with a non-tree-based method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "3be94357-e551-4094-b784-2df039216d33"
   },
   "source": [
    "### BONUS "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "db045898-1d2d-4af2-8e79-437c4c7546b4"
   },
   "source": [
    "#### Bonus: Use Count Vectorizer from scikit-learn to create features from the job descriptions. \n",
    "- Examine using count or binary features in the model\n",
    "- Re-evaluate your models using these. Does this improve the model performance? \n",
    "- What text features are the most valuable? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "4239e458-28bd-4675-8db3-c1d9c02b9854"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
